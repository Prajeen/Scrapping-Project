{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vr_snapshot_path = 'https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode='\n",
    "vr_performance_path = 'https://www.valueresearchonline.com/funds/fundperformance.asp?schemecode='\n",
    "\n",
    "details_file_path = 'C:/Prajeen/My Docs/Equity/1.Equity Details/1.Fund Analysis/Fund Details/'\n",
    "\n",
    "masterList = '1.fund_master_list.xlsx'\n",
    "graphExcel = '2.Weekly fund Graph.xlsx'\n",
    "dFormat = '%d/%m/%Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readExcel(excel):\n",
    "    print(excel)\n",
    "    master_wb = load_workbook(details_file_path+excel)\n",
    "    fundTypes = {}\n",
    "    sheets = master_wb.get_sheet_names()\n",
    "    for sheet in sheets:\n",
    "        fundTypes[sheet] = master_wb[sheet]\n",
    "    return fundTypes, master_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfFromXl(excel):\n",
    "    headers = list(excel.values)[0]\n",
    "    content = list(excel.values)[1:]\n",
    "    return pd.DataFrame(data=content,columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def returnFloat(contStr, toReplace=''):\n",
    "    if contStr == '-':\n",
    "        contStr = '0'\n",
    "    try:\n",
    "        val = float(contStr.replace(toReplace,''))\n",
    "    except ValueError:\n",
    "        return contStr\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValFromTable(column):\n",
    "    columnVal = list(column.stripped_strings)[0]\n",
    "    return columnVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeSnapshot(fundCode):\n",
    "    sShotResult = requests.get(vr_snapshot_path+fundCode)\n",
    "    parsedSS = BeautifulSoup(sShotResult.content, 'lxml')\n",
    "    snapContents = {}\n",
    "    \n",
    "    fundName = parsedSS.find('h1', class_='snapshot-fund-name')\n",
    "    snapContents['Fund Name'] = list(fundName.stripped_strings)[0]\n",
    "\n",
    "    baseInfo = parsedSS.find('div', class_ = 'pull-left fundHeadRight')\n",
    "    baseInfoStr = list(baseInfo.stripped_strings)\n",
    "    snapContents['Category'] = baseInfoStr[1]\n",
    "\n",
    "    dateInfo = parsedSS.find('div', class_ = 'pull-left change-date')\n",
    "    dateStr = list(dateInfo.stripped_strings)\n",
    "    snapContents['Date'] = (dateStr[0].split('as on'))[1].strip()\n",
    "    \n",
    "    return snapContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapePerformance(fundCode):\n",
    "    performResult = requests.get(vr_performance_path+fundCode)\n",
    "    parsedPerf = BeautifulSoup(performResult.content, 'lxml')\n",
    "    \n",
    "    perfContents = {}\n",
    "    perfInfo = parsedPerf.find_all('div', class_ = 'pull-left sectionHead margin_top15px')\n",
    "    \n",
    "    \n",
    "    riskMeasTable = perfInfo[3].find_all('tr')\n",
    "    val = list(riskMeasTable[0].find('th').stripped_strings)[0]\n",
    "    \n",
    "    trailRetTable=[]\n",
    "    if val.startswith('Trailing Returns'):\n",
    "        trailRetTable = riskMeasTable\n",
    "    else:\n",
    "        trailRetTable = perfInfo[4].find_all('tr')\n",
    "    \n",
    "    returnsInfo = trailRetTable[1].find_all('td')\n",
    "    perfContents['1W Ret'] = returnFloat(getValFromTable(returnsInfo[3]))\n",
    "    perfContents['1M Ret'] = returnFloat(getValFromTable(returnsInfo[4]))\n",
    "    perfContents['3M Ret'] = returnFloat(getValFromTable(returnsInfo[5]))\n",
    "    perfContents['6M Ret'] = returnFloat(getValFromTable(returnsInfo[6]))\n",
    "\n",
    "    return perfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createFundLine(fundColumns, fundDict):\n",
    "    line = []\n",
    "    for col in fundColumns:\n",
    "        line.append(fundDict[col])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getToday():\n",
    "    return date.today().strftime(dFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isDailyScrapingDone(sheetDf):\n",
    "    dateVal = sheetDf['Date']\n",
    "    latestDate = dateVal[len(dateVal)-1]\n",
    "      \n",
    "    if type(latestDate) is pd.tslib.Timestamp:\n",
    "        if latestDate.strftime(dFormat) == getToday():\n",
    "            return True\n",
    "    elif type(latestDate) is str:\n",
    "        if datetime.strptime(latestDate, dFormat).strftime(dFormat) == getToday():\n",
    "            return True   \n",
    "    elif type(latestDate) is pd._libs.tslib.Timestamp:\n",
    "        if latestDate.to_pydatetime().strftime(dFormat) == getToday():\n",
    "            return True  \n",
    "        \n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-03 12:43:35.110875\n",
      "1.fund_master_list.xlsx\n",
      "2.Weekly fund Graph.xlsx\n",
      "scraping global\n",
      "scraping fund 17132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Prajeen\\_Workstation\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping fund 17439\n",
      "scraping fund 17042\n",
      "scraping fund 17131\n",
      "scraping fund 17021\n",
      "scraping fund 16027\n",
      "scraping fund 12498\n",
      "scraping fund 17012\n",
      "scraping large & mid\n",
      "scraping fund 16573\n",
      "scraping fund 16581\n",
      "scraping fund 15845\n",
      "scraping fund 16194\n",
      "scraping fund 16770\n",
      "scraping fund 16266\n",
      "scraping fund 16267\n",
      "scraping fund 16569\n",
      "scraping multi\n",
      "scraping fund 15990\n",
      "scraping fund 16580\n",
      "scraping fund 16507\n",
      "scraping fund 34711\n",
      "scraping fund 15684\n",
      "scraping fund 16324\n",
      "scraping fund 25144\n",
      "scraping fund 17140\n",
      "scraping fund 16575\n",
      "scraping fund 15714\n",
      "scraping tech\n",
      "scraping fund 16018\n",
      "scraping fund 31368\n",
      "scraping fund 15878\n",
      "scraping fund 17526\n",
      "scraping fund 15864\n",
      "scraping pharma\n",
      "scraping fund 16150\n",
      "scraping fund 31352\n",
      "scraping fund 15932\n",
      "scraping fund 16327\n",
      "scraping value\n",
      "scraping fund 30921\n",
      "scraping fund 16175\n",
      "scraping fund 16498\n",
      "scraping fund 15879\n",
      "scraping fund 16341\n",
      "scraping fund 16952\n",
      "scraping fund 15989\n",
      "scraping fund 16719\n",
      "scraping elss\n",
      "scraping fund 16200\n",
      "scraping fund 16739\n",
      "scraping fund 16493\n",
      "scraping fund 16650\n",
      "scraping fund 16454\n",
      "scraping fund 15889\n",
      "scraping fund 29162\n",
      "scraping fund 16186\n",
      "scraping fund 16803\n",
      "scraping fund 16594\n",
      "scraping fund 15688\n",
      "scraping fund 20683\n",
      "scraping fund 16868\n",
      "scraping large\n",
      "scraping fund 15883\n",
      "scraping fund 16198\n",
      "scraping fund 15831\n",
      "scraping fund 16192\n",
      "scraping fund 16120\n",
      "scraping fund 15841\n",
      "scraping fund 15682\n",
      "scraping fund 17352\n",
      "scraping hybrid\n",
      "scraping fund 15702\n",
      "scraping fund 16215\n",
      "scraping fund 15815\n",
      "scraping fund 15829\n",
      "scraping fund 16521\n",
      "scraping fund 16159\n",
      "scraping fund 16264\n",
      "scraping fund 17357\n",
      "scraping fund 16338\n",
      "scraping fund 15793\n",
      "scraping fund 17017\n",
      "scraping fund 17375\n",
      "scraping fund 32609\n",
      "scraping fund 17866\n",
      "scraping small\n",
      "scraping fund 26133\n",
      "scraping fund 16182\n",
      "scraping fund 16010\n",
      "scraping fund 15935\n",
      "scraping fund 16617\n",
      "scraping fund 16325\n",
      "scraping fund 26860\n",
      "scraping fund 16112\n",
      "scraping fund 16411\n",
      "scraping fund 15787\n",
      "scraping fund 17116\n",
      "scraping mid\n",
      "scraping fund 16280\n",
      "scraping fund 16589\n",
      "scraping fund 15690\n",
      "scraping fund 16114\n",
      "scraping fund 16807\n",
      "scraping fund 22367\n",
      "scraping infra\n",
      "scraping fund 16514\n",
      "scraping fund 16275\n",
      "scraping fund 17695\n",
      "scraping fund 16074\n",
      "scraping fund 15979\n",
      "scraping fund 16508\n",
      "scraping fund 16410\n",
      "scraping fund 16138\n",
      "scraping fund 16330\n",
      "scraping fund 17371\n",
      "scraping fund 16672\n",
      "scraping fund 17161\n",
      "scraping fund 16774\n",
      "scraping bank\n",
      "scraping fund 16702\n",
      "scraping fund 16048\n",
      "scraping fund 15936\n",
      "scraping fund 22526\n",
      "scraping fund 15967\n",
      "scraping fund 29463\n",
      "scraping fund 6175\n",
      "scraping fund 6157\n",
      "scraping fund 31406\n",
      "2018-12-03 12:48:47.694660\n"
     ]
    }
   ],
   "source": [
    "print(str(datetime.now()))\n",
    "\n",
    "fundTypes, masterFile = readExcel(masterList)\n",
    "graphDetails, graphFile = readExcel(graphExcel)\n",
    "evalSheet = graphDetails['evaluation']\n",
    "\n",
    "for sheet in list(fundTypes.keys()):\n",
    "    print('scraping '+ sheet)\n",
    "    sheetDf = getDfFromXl(fundTypes[sheet])\n",
    "    \n",
    "    if isDailyScrapingDone(getDfFromXl(graphDetails[sheet])):\n",
    "        continue\n",
    "    fundLine = []\n",
    "    isDateUpdated = False\n",
    "    \n",
    "    for fundCode in sheetDf['Fund Code'].values:\n",
    "        print('scraping fund '+ str(fundCode))\n",
    "        fundDict = {}\n",
    "        evalLine =[]\n",
    "        \n",
    "        fundDict.update(scrapeSnapshot(str(fundCode)))\n",
    "        fundDict.update(scrapePerformance(str(fundCode)))\n",
    "        \n",
    "        if isDateUpdated is False:\n",
    "            fundLine.append(getToday())\n",
    "            isDateUpdated = True\n",
    "          \n",
    "        fundLine.append(round(fundDict['1W Ret'],1))\n",
    "        fundLine.append(round(fundDict['1M Ret'],1))\n",
    "        fundLine.append(round(fundDict['3M Ret'],1))\n",
    "        fundLine.append(round(fundDict['6M Ret'],1))\n",
    "        \n",
    "        evalLine.append(sheet)\n",
    "        evalLine.append(getToday())\n",
    "        evalLine.append(fundDict['Category'])\n",
    "        evalLine.append(fundDict['Date'])\n",
    "        evalLine.append(fundDict['1W Ret'])\n",
    "        evalLine.append(fundDict['1M Ret'])\n",
    "        evalLine.append(fundDict['3M Ret'])\n",
    "        evalLine.append(fundDict['6M Ret'])\n",
    "        \n",
    "        evalSheet.append(evalLine)\n",
    "    \n",
    "    fundDetails = graphDetails[sheet]\n",
    "    fundDetails.append(fundLine)\n",
    "    \n",
    "graphFile.save(details_file_path+graphExcel)\n",
    "\n",
    "\n",
    "print(str(datetime.now()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
