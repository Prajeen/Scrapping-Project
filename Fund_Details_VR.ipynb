{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vr_snapshot_path = 'https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode='\n",
    "vr_performance_path = 'https://www.valueresearchonline.com/funds/fundperformance.asp?schemecode='\n",
    "vr_portfolio_path = 'https://www.valueresearchonline.com/funds/portfoliovr.asp?schemecode='\n",
    "vr_analysis_path = 'https://www.valueresearchonline.com/funds/fundanalysis.asp?schemecode='\n",
    "\n",
    "et_performance_path = 'https://economictimes.indiatimes.com/mfreturns/schemeid-'\n",
    "et_portfolio_path = 'https://economictimes.indiatimes.com/mfportfolio/schemeid-'\n",
    "\n",
    "details_file_path = 'C:/Prajeen/My Docs/Equity/1.Equity Details/1.Fund Analysis/Fund Details/'\n",
    "\n",
    "masterList = '1.fund_master_list.xlsx'\n",
    "#masterList = '3.Single_fund_list.xlsx'\n",
    "\n",
    "isSingleFundType = True\n",
    "singleFundType = 'large cap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readMasterExcel():\n",
    "    master_wb = load_workbook(details_file_path+masterList)\n",
    "    fundTypes = {}\n",
    "    sheets = master_wb.get_sheet_names()\n",
    "    for sheet in sheets:\n",
    "        fundTypes[sheet] = master_wb[sheet]\n",
    "    return fundTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfFromXl(excel):\n",
    "    headers = list(excel.values)[0]\n",
    "    content = list(excel.values)[1:]\n",
    "    return pd.DataFrame(data=content,columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeTable(tableInfo, indexVal, topRowToIgnore=0 ):\n",
    "    holdingsRow = tableInfo.find_all('tr')[topRowToIgnore:]\n",
    "    holdTable = []\n",
    "    for row in range(len(holdingsRow)):\n",
    "        holdTable.append(list(holdingsRow[row].stripped_strings))\n",
    "    \n",
    "    tableDf = pd.DataFrame(holdTable[1:], index=[[indexVal]*len(holdTable[1:])], columns=holdTable[:1][0])\n",
    "    return tableDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnFloat(contStr, toReplace=''):\n",
    "    try:\n",
    "        val = float(contStr.replace(toReplace,''))\n",
    "    except ValueError:\n",
    "        return contStr\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValFromTable(column):\n",
    "    columnVal = list(column.stripped_strings)[0]\n",
    "    return columnVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeSnapshot(fundCode):\n",
    "    sShotResult = requests.get(vr_snapshot_path+fundCode)\n",
    "    parsedSS = BeautifulSoup(sShotResult.content, 'lxml')\n",
    "    snapContents = {}\n",
    "    \n",
    "    fundName = parsedSS.find('h1', class_='snapshot-fund-name')\n",
    "    rating = parsedSS.find('span', itemprop = 'rating')\n",
    "    snapContents['Fund Name'] = list(fundName.stripped_strings)[0]\n",
    "    snapContents['Fund Code'] = int(fundCode)\n",
    "    snapContents['Rating'] = int(0 if len(list(rating.stripped_strings)) is 0 else list(rating.stripped_strings)[0] )\n",
    "    \n",
    "    statusHtml = parsedSS.find('li', class_ = 'pull-right padding_right_none')\n",
    "    statusString = list(statusHtml.stripped_strings)[0]\n",
    "    status = ((statusString.split(':')[1]).split('|')[0]).strip()\n",
    "    snapContents['Status'] = status\n",
    "    \n",
    "    if status.startswith('Closed for subscription'):\n",
    "        return snapContents, True\n",
    "\n",
    "    baseInfo = parsedSS.find('div', class_ = 'pull-left fundHeadRight')\n",
    "    baseInfoStr = list(baseInfo.stripped_strings)\n",
    "    snapContents['Category'] = baseInfoStr[1]\n",
    "    snapContents['Assets'] = baseInfoStr[4].split('\\r\\n')[0]\n",
    "    snapContents['Exp Ratio'] = baseInfoStr[6].split('%')[0]\n",
    "\n",
    "    dateInfo = parsedSS.find('div', class_ = 'pull-left change-date')\n",
    "    dateStr = list(dateInfo.stripped_strings)\n",
    "    snapContents['Date'] = (dateStr[0].split('as on'))[1].strip()\n",
    "\n",
    "    basicDetailsInfo = parsedSS.find('div', class_ = 'pull-left sectionHead margin_top15px basic-and-investment-details')\n",
    "    basicDetailsList = list(basicDetailsInfo.stripped_strings)\n",
    "    snapContents['Launch Date'] = basicDetailsList[4]\n",
    "    snapContents['Benchmark'] = basicDetailsList[6]\n",
    "    snapContents['Riskometer'] = basicDetailsList[8]\n",
    "    snapContents['Risk Grade'] = basicDetailsList[10]\n",
    "    snapContents['Return Grade'] = basicDetailsList[12]\n",
    "    snapContents['T/O %'] = returnFloat(basicDetailsList[14],'%')\n",
    "    snapContents['Type'] = basicDetailsList[16]\n",
    "    snapContents['Ret sin Lau%'] = returnFloat(basicDetailsList[19],'%')\n",
    "    snapContents['Mini Inv'] = returnFloat(basicDetailsList[23],',')\n",
    "    snapContents['Min SIP'] = returnFloat(basicDetailsList[31],',')\n",
    "    snapContents['Exit Load'] = basicDetailsList[43]\n",
    "    \n",
    "    return snapContents, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapePerformance(fundCode):\n",
    "    performResult = requests.get(vr_performance_path+fundCode)\n",
    "    parsedPerf = BeautifulSoup(performResult.content, 'lxml')\n",
    "    \n",
    "    perfContents = {}\n",
    "    perfInfo = parsedPerf.find_all('div', class_ = 'pull-left sectionHead margin_top15px')\n",
    "\n",
    "    riskMeasTable = perfInfo[3].find_all('tr')\n",
    "    \n",
    "    val = list(riskMeasTable[0].find('th').stripped_strings)[0]\n",
    "    if val.startswith('Risk Measures'):  \n",
    "        fundInfo = riskMeasTable[1].find_all('td')\n",
    "        perfContents['Mean'] = returnFloat(getValFromTable(fundInfo[1]))\n",
    "        perfContents['Std Dev'] =returnFloat(getValFromTable(fundInfo[2]))\n",
    "        perfContents['Sharpe'] = returnFloat(getValFromTable(fundInfo[3]))\n",
    "        perfContents['Sortino'] = returnFloat(getValFromTable(fundInfo[4]))\n",
    "        perfContents['Beta'] = returnFloat(getValFromTable(fundInfo[5]))\n",
    "        perfContents['Alpha'] = returnFloat(getValFromTable(fundInfo[6]))\n",
    "\n",
    "        if len(riskMeasTable) > 4:\n",
    "            fundRank = riskMeasTable[4].find_all('td')\n",
    "            perfContents['Beta Rank'] = returnFloat(getValFromTable(fundRank[5]))\n",
    "            perfContents['Alpha Rank'] = returnFloat(getValFromTable(fundRank[6]))\n",
    "\n",
    "    trailRetTable=[]\n",
    "    if val.startswith('Trailing Returns'):\n",
    "        trailRetTable = riskMeasTable\n",
    "    else:\n",
    "        trailRetTable = perfInfo[4].find_all('tr')\n",
    "        \n",
    "    returnsInfo = trailRetTable[1].find_all('td')\n",
    "    perfContents['YTD Ret'] = returnFloat(getValFromTable(returnsInfo[1]))\n",
    "    perfContents['1W Ret'] = returnFloat(getValFromTable(returnsInfo[3]))\n",
    "    perfContents['1M Ret'] = returnFloat(getValFromTable(returnsInfo[4]))\n",
    "    perfContents['3M Ret'] = returnFloat(getValFromTable(returnsInfo[5]))\n",
    "    perfContents['6M Ret'] = returnFloat(getValFromTable(returnsInfo[6]))\n",
    "    perfContents['1Y Ret'] = returnFloat(getValFromTable(returnsInfo[7]))\n",
    "    perfContents['3Y Ret'] = returnFloat(getValFromTable(returnsInfo[8]))\n",
    "\n",
    "    if len(trailRetTable) > 4:\n",
    "        returnsRank = trailRetTable[4].find_all('td')\n",
    "        perfContents['YTD Rnk'] = returnFloat(getValFromTable(returnsRank[1]))\n",
    "        perfContents['1W Rnk'] = returnFloat(getValFromTable(returnsRank[3]))\n",
    "        perfContents['1M Rnk'] = returnFloat(getValFromTable(returnsRank[4]))\n",
    "        perfContents['3M Rnk'] = returnFloat(getValFromTable(returnsRank[5]))\n",
    "        perfContents['6M Rnk'] = returnFloat(getValFromTable(returnsRank[6]))\n",
    "        perfContents['1Y Rnk'] = returnFloat(getValFromTable(returnsRank[7]))\n",
    "        perfContents['3Y Rnk'] = returnFloat(getValFromTable(returnsRank[8]))\n",
    "\n",
    "    return perfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapePortfolio(fundCode):\n",
    "    portfolioResult = requests.get(vr_portfolio_path+str(fundCode))\n",
    "    parsedPortfol = BeautifulSoup(portfolioResult.content, 'lxml')\n",
    "    \n",
    "    pfContents = {}\n",
    "    valInfo = parsedPortfol.find_all('td', class_ ='padding_top_none padding_bottom_none border_bottom_none')\n",
    "    valList = list(valInfo[1].stripped_strings)\n",
    "\n",
    "    pfContents['Num of Stks'] = returnFloat(valList[2])\n",
    "    pfContents['Top 10 Stks%'] = returnFloat(valList[4])\n",
    "    pfContents['Top 5 Stks%'] = returnFloat(valList[6])\n",
    "    pfContents['Top 3 sect%'] = returnFloat(valList[8])\n",
    "    pfContents['P/B Ratio'] = returnFloat(valList[10])\n",
    "    pfContents['P/E Ratio'] = returnFloat(valList[12])\n",
    "\n",
    "    aggInfo = parsedPortfol.find_all('td', class_ = 'align_right equity-fund-cell')\n",
    "    if len(aggInfo)>0:\n",
    "        pfContents['mkt cap(Cr)'] = returnFloat(getValFromTable(aggInfo[0]),',')\n",
    "        pfContents['Giant(%)'] = returnFloat(getValFromTable(aggInfo[1]))\n",
    "        pfContents['Large(%)'] = returnFloat(getValFromTable(aggInfo[2]))\n",
    "        pfContents['Mid(%)'] = returnFloat(getValFromTable(aggInfo[3]))\n",
    "        pfContents['Small(%)'] = returnFloat(getValFromTable(aggInfo[4]))\n",
    "        pfContents['Tiny(%)'] = returnFloat(getValFromTable(aggInfo[5]))\n",
    "\n",
    "    holdingsInfo = parsedPortfol.find_all('table', class_ ='fund-snapshot-port-holdings-equity')\n",
    "    pf = scrapeTable(holdingsInfo[0],int(fundCode), 1)\n",
    "    \n",
    "    return pfContents, pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeAnalysis(fundCode):\n",
    "    analysisResult = requests.get(vr_analysis_path+str(fundCode))\n",
    "    parsedAnalysis = BeautifulSoup(analysisResult.content, 'lxml')\n",
    "    \n",
    "    anContents = {}\n",
    "    analysisInfo = parsedAnalysis.find_all('tr', class_='')\n",
    "    anContents['Fund Manager'] = list(analysisInfo[2].stripped_strings)[1]\n",
    "    \n",
    "    return anContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrapeEtPerf(fundCode):\n",
    "    etPerfResult = requests.get(et_performance_path+str(fundCode)+'.cms')\n",
    "    parsedEtPerf = BeautifulSoup(etPerfResult.content, 'lxml')\n",
    "    \n",
    "    etPerfContents = {}\n",
    "    etPerfInfo = parsedEtPerf.find_all('div', class_='tabing')\n",
    "\n",
    "    currentYrInfo = etPerfInfo[0].find_all('div', class_ = 'current')\n",
    "    currentYrVals = list(currentYrInfo[0].stripped_strings)\n",
    "    etPerfContents['YTD Q1'] = returnFloat(currentYrVals[1])\n",
    "    etPerfContents['YTD Q2'] = returnFloat(currentYrVals[2])\n",
    "    etPerfContents['YTD Q3'] = returnFloat(currentYrVals[3])\n",
    "    etPerfContents['YTD Q4'] = returnFloat(currentYrVals[4])\n",
    "\n",
    "    previousYrInfo = etPerfInfo[0].find_all('div', class_ = 'withbackground')\n",
    "    \n",
    "    if len(previousYrInfo)>0:\n",
    "        oneYrVals = list(previousYrInfo[0].stripped_strings)\n",
    "        etPerfContents['1Y Q1'] = returnFloat(oneYrVals[1])\n",
    "        etPerfContents['1Y Q2'] = returnFloat(oneYrVals[2])\n",
    "        etPerfContents['1Y Q3'] = returnFloat(oneYrVals[3])\n",
    "        etPerfContents['1Y Q4'] = returnFloat(oneYrVals[4])\n",
    "\n",
    "        if len(previousYrInfo)>1:\n",
    "            twoYrVals = list(previousYrInfo[1].stripped_strings)\n",
    "            etPerfContents['2Y Q1'] = returnFloat(twoYrVals[1])\n",
    "            etPerfContents['2Y Q2'] = returnFloat(twoYrVals[2])\n",
    "            etPerfContents['2Y Q3'] = returnFloat(twoYrVals[3])\n",
    "            etPerfContents['2Y Q4'] = returnFloat(twoYrVals[4])\n",
    "\n",
    "    etTechTerms = parsedEtPerf.find_all('div', class_='borDotted')\n",
    "    etPerfContents['R.Squared'] = returnFloat(list(etTechTerms[3].stripped_strings)[3])\n",
    "    etPerfContents['Treynor'] = returnFloat(list(etTechTerms[6].stripped_strings)[3])\n",
    "    etPerfContents['Inf Ratio'] = returnFloat(list(etTechTerms[7].stripped_strings)[3])\n",
    "    \n",
    "    return etPerfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeEtPf(fundCode):\n",
    "    etPfResult = requests.get(et_portfolio_path+str(fundCode)+'.cms')\n",
    "    parsedEtPf = BeautifulSoup(etPfResult.content, 'lxml')\n",
    "    \n",
    "    etPfContents = {}\n",
    "    etPfInfo = parsedEtPf.find_all('div', class_='pRow')\n",
    "    etPfContents['Eqty(%)'] = returnFloat(list(etPfInfo[0].stripped_strings)[1].split('%')[0])\n",
    "    etPfContents['Dbt(%)'] = returnFloat(list(etPfInfo[1].stripped_strings)[1].split('%')[0])\n",
    "    etPfContents['Otr(%)'] = returnFloat(list(etPfInfo[2].stripped_strings)[1].split('%')[0])\n",
    "    \n",
    "    return etPfContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createFundLine(fundColumns, fundDict):\n",
    "    line = []\n",
    "    for col in fundColumns:\n",
    "        try:\n",
    "            colValue = fundDict[col]\n",
    "        except KeyError:\n",
    "            colValue = ''\n",
    "        line.append(colValue)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 17:55:01.010959\n",
      "hybrid equity\n",
      "inside first\n",
      "inside second\n",
      "small cap\n",
      "inside first\n",
      "inside second\n",
      "mid cap\n",
      "inside first\n",
      "inside second\n",
      "elss\n",
      "inside first\n",
      "inside second\n",
      "global\n",
      "inside first\n",
      "inside second\n",
      "technology\n",
      "inside first\n",
      "inside second\n",
      "multi cap\n",
      "inside first\n",
      "inside second\n",
      "banking\n",
      "inside first\n",
      "inside second\n",
      "infrastructure\n",
      "inside first\n",
      "inside second\n",
      "large cap\n",
      "inside first\n",
      "Redding type = large cap\n",
      "starting processing large cap\n",
      "starting scrapping 17140\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15883\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16198\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15831\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16192\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16120\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15845\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16194\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16055\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15841\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16575\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16770\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16569\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16155\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15682\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 16341\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "starting scrapping 15714\n",
      "finished snapshot\n",
      "finished performance\n",
      "finished analysis\n",
      "finished ER performance\n",
      "finished ET portfolio\n",
      "finished portfolio\n",
      "created Line\n",
      "large cap.... has been saved\n",
      "2018-05-08 18:00:56.375634\n"
     ]
    }
   ],
   "source": [
    "print(str(datetime.now()))\n",
    "\n",
    "fundTypes = readMasterExcel()\n",
    "\n",
    "for sheet in list(fundTypes.keys()):\n",
    "    print(sheet)\n",
    "    if isSingleFundType is True:\n",
    "        print('inside first')\n",
    "        if singleFundType != sheet:\n",
    "            print('inside second')\n",
    "            continue\n",
    "    try:\n",
    "        load_workbook(details_file_path+sheet+date.today().strftime('_%d_%b_%Y')+'.xlsx')\n",
    "        print(sheet + ' has already been read today!!')\n",
    "        continue\n",
    "    except FileNotFoundError:\n",
    "        print('Redding type = '+sheet)\n",
    "        pass\n",
    "    \n",
    "    sheetDf = getDfFromXl(fundTypes[sheet])\n",
    "    print('starting processing '+ sheet)\n",
    "    \n",
    "    wb = Workbook()\n",
    "    fundSheet = wb.active\n",
    "    fundSheet.title = 'funds'\n",
    "    pfSheet = wb.create_sheet(title='portfolio')\n",
    "    \n",
    "    fundSheet.append(list(sheetDf.columns))\n",
    "        \n",
    "    for fundCode in sheetDf['Fund Code'].values:\n",
    "        fundDict = {}\n",
    "        print('starting scrapping '+ str(fundCode))\n",
    "        \n",
    "        #fundDict.update(scrapeSnapshot(str(fundCode)))\n",
    "        snFund, isStatusClosed = scrapeSnapshot(str(fundCode))\n",
    "        fundDict.update(snFund)\n",
    "        print('finished snapshot')\n",
    "        \n",
    "        if isStatusClosed is False:  \n",
    "            fundDict.update(scrapePerformance(str(fundCode)))\n",
    "            print('finished performance')\n",
    "            fundDict.update(scrapeAnalysis(str(fundCode)))\n",
    "            print('finished analysis')\n",
    "            fundDict.update(scrapeEtPerf(str(fundCode)))\n",
    "            print('finished ER performance')\n",
    "            fundDict.update(scrapeEtPf(str(fundCode)))\n",
    "            print('finished ET portfolio')\n",
    "            \n",
    "            if not sheet.startswith('global'):\n",
    "                pfFund, pf = scrapePortfolio(str(fundCode))\n",
    "                print('finished portfolio')\n",
    "                fundDict.update(pfFund)\n",
    "                for line in dataframe_to_rows(pf, index=False):\n",
    "                    pfSheet.append(line)\n",
    "                \n",
    "        fundLine = createFundLine(sheetDf.columns, fundDict)\n",
    "        print('created Line')\n",
    "        fundSheet.append(fundLine)\n",
    "    \n",
    "    \n",
    "    wb.save(details_file_path+sheet+date.today().strftime('_%d_%b_%Y')+'.xlsx')\n",
    "    print(sheet+'.... has been saved')\n",
    "    \n",
    "print(str(datetime.now()))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
